1. Use launch_prm_eval.sh to launch inference of VisualPRM-8B (PRM) or similar to judge every Step Level Candidate or Non-Greedy Candidate from outputs generated by a Policy Model.
    - Currently we standardize using the outputs from the pipeline generated with Q3B_full PRM.
    - This outputs the same JSON file but with a new "step_agg" or "non_greedy" key with the corresponding "chosen_candidate" out of the list of candidates, selected based on the best_reward score
        - for "step_agg", scoring works by splitting every candidate solution first into steps, scoring each step with the PRM, then taking the average reward of all steps (note: will be affected by number of steps in the candidate solution, the only normalization factor is the number of steps that vary - VPRM forces 12 steps)
        - for "non_greedy", PRM scores the entire candidate solution and selects the candidate with the highest score
        - After selecting the "chosen_candidate" index, we need to extract the answer from the chosen candidate solution, then compute the final score selected by this solution
2. Use extract_ans.py to extract the answer from the chosen candidate solution
3. Use compute_score.py to compute the final score selected by this TTS method (NG or Step Agg)