import os
import math
import json
import numpy as np
from tqdm import tqdm
from pathlib import Path

# from openai import OpenAI
from PIL import Image
from io import BytesIO

import argparse
import re
from concurrent.futures import ThreadPoolExecutor

from judge import MathVistaJudgeModel

def safe_isnan(val):
    try:
        return math.isnan(val)
    except (TypeError, ValueError):
        return False


def extract_boxed(s):
    # Match both \boxed{...} and \\boxed{...} patterns to handle escape sequence issues
    # Use raw string in pattern but flexible matching for corrupted backslashes
    patterns = [
        r"\\boxed\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}",  # Standard \boxed{...}
        r"\x08oxed\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}",  # Handle corrupted \b -> \x08 from LLM string output, as LLM may not know to escape the backslash all the time
        r"\nboxed\{([^{}]*(?:\{[^{}]*\}[^{}]*)*)\}",  # Handle \nboxed (generated by 7B model)
        r"\\\[(.*?)\]",
        r"```(?:\n)?(.*?)\n?```",
    ]

    all_matches = []
    for pattern in patterns:
        matches = list(re.finditer(pattern, s))
        all_matches.extend(matches)

    if not all_matches:
        return None

    # Sort by position and return the LATEST match
    all_matches.sort(key=lambda m: m.start())
    return all_matches[-1].group(1).strip()

def load_json(file_path):
    """
    Load a JSON file and return its contents as a Python object (dict or list).
    """
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data

def save_json(data, filepath, indent=2):
    """
    Save Python object as JSON file, creating parent directories if needed.

    Args:
        data: Python object (dict, list, etc.)
        filepath: path to save the JSON file
        indent: indentation level for pretty printing (default=2)
    """
    # Ensure parent directory exists
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=indent)

def process_judge_sample(args):
    """
    Process a single judge sample in parallel.
    
    Args:
        args: Tuple of (j_sample, data_item, filename)
        
    Returns:
        Dict with processing results
    """
    j_sample, data_item, filename = args
    
    # Create judge model instance for this worker
    judge_model = MathVistaJudgeModel(model_path="gpt-4.1", temperature=0.0)
    
    try:
        sidx = j_sample[0]
        question = data_item['annotation']['question']
        
        # Extract options based on dataset type
        if "puzzleVQA" in filename or "AlgoPuzzleVQA" in filename:
            options = data_item['annotation']['options']
        elif "MMMU" in filename:
            if data_item['annotation']['question_type'] in [
                "multi-choice",
                "multiple-choice",
            ]:
                option_chars = ["A", "B", "C", "D", "E", "F", "G", "H", "I"]
                options = []
                for option_char in option_chars:
                    option_val = data_item['annotation'][option_char]
                    if option_val != None and not safe_isnan(option_val):
                        options.append(option_val)
            else:
                options = []
        elif "mathvista" in filename:
            if data_item['annotation']['question_type'] in [
                "multi-choice",
                "multiple-choice",
            ]:
                options = data_item['annotation']['choices']
            else:
                options = []
        elif "mathvision".lower() in filename.lower():
            # Fixed bug: was using undefined 'sample', now using 'data_item'
            annotation = data_item["annotation"]
            question = annotation['question']
            options = annotation['options']
        else:
            options = []
        
        # Process with judge model
        output = judge_model.judge_single_sample(question, options, j_sample[2])
        extracted_answer = output["judge_output"]
        extraction_method = output["extraction_method"]
        judge_prompt = output["judge_prompt"]
        
        return {
            'sidx': sidx,
            'success': True,
            'pred_answer': extracted_answer,
            'judge_output': output,
            'error': None
        }
        
    except Exception as e:
        return {
            'sidx': j_sample[0] if j_sample else None,
            'success': False,
            'pred_answer': f"Processing error: {str(e)}",
            'judge_output': {"judge_output": f"Error: {str(e)}", "extraction_method": "Error", "judge_prompt": ""},
            'error': str(e)
        }

def main():
    parser = argparse.ArgumentParser(
        description="Extract Answer from candidates"
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        required = True,
        help="Path to step traces",
    )
    parser.add_argument(
        "--dev-mode",
        action="store_true",
        help="Dev mode: Just to get failure statistics. Doesnt run judge extraction"
    )
    parser.add_argument(
        "--max-workers",
        type=int,
        default=100,
        help="Maximum number of parallel workers for ThreadPoolExecutor (default: 100)"
    )

    args = parser.parse_args()

    root_dir = Path(args.data_dir)

    error_samples = []
    for idx, path in enumerate(root_dir.rglob("*.json")):

        print(f"{idx}: {path}")

        filename = path.name

        data = load_json(path)

        null_counter = 0

        judge_samples = [] # --> Append samples in format (sample_idx, candidate_idx, candidate solution last st)

        for sidx, sample in enumerate(tqdm(data)):

            # if len(sample['iteration_history']) < 1:
            #     continue
            
            # for cidx, candidate in enumerate(sample['iteration_history'][0]['candidates_info']):
            #     candidate_soln = candidate['candidate_step']
            #     pred = extract_boxed(candidate_soln)

            #     if pred == None:
            #         null_counter += 1
            #         last_step = candidate['candidate_step'].replace("<|im_end|>", "").replace("<end_of_turn>", "").rstrip().split("\n\n")[-1]

            #         if len(last_step) < 1000:
            #             judge_samples.append(
            #                 (sidx, cidx, last_step)
            #                 # (sidx, cidx, candidate['candidate_step'].replace("<|im_end|>", "").replace("<end_of_turn>", "").rstrip())
            #             )

            #     candidate["pred_answer"] = pred

            # instead of extracting pred_answer from all candidates, we can just extract it from the chosen candidate
            if "non_greedy" in sample and sample["non_greedy"]:
                chosen_candidate_soln = sample['iteration_history'][0]['candidates_info'][sample['non_greedy']["chosen_candidate"]]
                chosen_candidate_idx = sample['non_greedy']["chosen_candidate"]
            elif "step_agg" in sample and sample["step_agg"]:
                chosen_candidate_soln = sample['iteration_history'][0]['candidates_info'][sample['step_agg']["chosen_candidate"]]
                chosen_candidate_idx = sample['step_agg']["chosen_candidate"]
            else:
                error_samples.append(sample)
                print(f"Error in sample: {sample}")
                # raise ValueError(f"No chosen candidate found for sample {sidx}")

            pred = extract_boxed(chosen_candidate_soln["candidate_step"])

            if pred == None:
                null_counter += 1
                last_step = chosen_candidate_soln["candidate_step"].replace("<|im_end|>", "").replace("<end_of_turn>", "").rstrip().split("\n\n")[-1] # TODO: or can pick up to 3-5 steps and join them before answer extraction
                if len(last_step) < 1000:
                    judge_samples.append(
                        (sidx, chosen_candidate_idx, last_step)
                    )
            else:
                sample["pred_answer"] = pred # save the new sample obj with the extracted answer

        # print("Error samples: ", len(error_samples))
        # print("Extraction Failed: ", null_counter)
        # print("Judge_samples: ", len(judge_samples))

        if args.dev_mode:
            continue
        
        # Parallel processing of judge samples
        if judge_samples:
            print(f"Processing {len(judge_samples)} samples with parallel ThreadPoolExecutor...")
            
            # Validate judge_samples indices before processing
            invalid_indices = [j[0] for j in judge_samples if j[0] < 0 or j[0] >= len(data)]
            if invalid_indices:
                print(f"WARNING: Found {len(invalid_indices)} invalid indices in judge_samples: {invalid_indices[:5]}...")
            
            # Prepare arguments for parallel processing
            args_list = [(j_sample, data[j_sample[0]], filename) for j_sample in judge_samples]
            
            # Process in parallel with ThreadPoolExecutor
            results = []
            with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
                # executor.map preserves order, but we use sidx for mapping anyway
                for result in tqdm(
                    executor.map(process_judge_sample, args_list),
                    total=len(judge_samples),
                    desc="Judge Sample Processing"
                ):
                    results.append(result)
            
            # Apply results back to data structure
            # Check for duplicate sidx in results (should never happen)
            result_sidx_list = [r['sidx'] for r in results if r['sidx'] is not None]
            if len(result_sidx_list) != len(set(result_sidx_list)):
                print(f"WARNING: Found duplicate sidx values in results - this indicates a logic error")
            
            success_count = 0
            error_count = 0
            for result in results:
                sidx = result['sidx']
                
                # Validation: ensure sidx is valid
                if sidx is None or sidx < 0 or sidx >= len(data):
                    print(f"ERROR: Invalid sidx {sidx} for data array of length {len(data)}")
                    error_count += 1
                    continue
                
                if result['success']:
                    data[sidx]['pred_answer'] = result['pred_answer']
                    data[sidx]['judge_output'] = result['judge_output']
                    success_count += 1
                else:
                    print(f"Error processing sample {sidx}: {result['error']}")
                    # Still set the error result so we don't lose the sample
                    data[sidx]['pred_answer'] = result['pred_answer']
                    data[sidx]['judge_output'] = result['judge_output']
                    error_count += 1
            
            print(f"Parallel processing completed: {success_count} successful, {error_count} errors")
        else:
            print("No samples requiring judge processing")
        
        # break
        extracted_ans_dir = "./outputs/extracted_ans_outputs/PRM_V8B" # TODO: Change this to the correct model name
        policy_model = "g27b"
        filename_without_ext = path.stem  # Gets filename without extension
        save_json(data, f"{extracted_ans_dir}/{policy_model}_policy/{filename_without_ext}_extracted_ans.json")

        print("Error samples when extracting answer: ", len(error_samples))
        print("Null Answers: ", null_counter)
        print("Judge_samples: ", len(judge_samples))
        print("file saved to: ", f"{extracted_ans_dir}/{policy_model}_policy/{filename_without_ext}_extracted_ans.json")

if __name__ == "__main__":
    main()